{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f140c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: torch<3,>=2.3 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from bitsandbytes) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.128.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (3.11.5)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: pydub in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.0.21)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio) (0.40.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from gradio-client==2.0.2->gradio) (2024.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading bitsandbytes-0.49.0-py3-none-win_amd64.whl (54.7 MB)\n",
      "   ---------------------------------------- 0.0/54.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.5/54.7 MB 27.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 10.5/54.7 MB 25.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 13.4/54.7 MB 22.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 16.0/54.7 MB 19.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 18.6/54.7 MB 17.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 21.8/54.7 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 25.4/54.7 MB 17.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 29.6/54.7 MB 17.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 33.6/54.7 MB 17.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 35.1/54.7 MB 16.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 40.1/54.7 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 45.4/54.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 49.5/54.7 MB 17.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  53.5/54.7 MB 17.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  54.5/54.7 MB 17.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 54.7/54.7 MB 17.1 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.49.0\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\yeshwanth\\anaconda3\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl (18.4 MB)\n",
      "   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.7/18.4 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 7.1/18.4 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 9.4/18.4 MB 15.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 12.3/18.4 MB 14.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 14.9/18.4 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.6/18.4 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.4/18.4 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.7 python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes transformers accelerate gradio\n",
    "!pip install PyMuPDF python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2576e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import gradio as gr\n",
    "import fitz  # PyMuPDF for PDF\n",
    "import docx  # For DOCX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96719f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b7cb27327a4c6998e7215a52400348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yeshwanth\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yeshwanth\\.cache\\huggingface\\hub\\models--microsoft--phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb49fbe0b5464e2a9e3d0e43f6bfcc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b45b3b57fec494b807e539d1eb9b5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b022633ad0346cbb68b854bd8926338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8321cd0ff292436897c4ec0f730d7a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c87e7c89604280aedbfd3ee7641d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d18043f3e2426e96040d2d7cb2e5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67807696b4004a779cf175e1effcb4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b607d864e14d99ae0e6c392a58c9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dfca553ad84e04a1b47a8efb902940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6f5bc492e64c7aa45943dc13df883f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f0ed8fedb043ffb493998f711bd9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device set to: {device}\")\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95123c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_text(text, max_tokens=1000):\n",
    "    sentences = text.split('. ')\n",
    "    chunks, current_chunk = [], \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_tokens:\n",
    "            current_chunk += sentence + \". \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \". \"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d2e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0bfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\"\n",
    "    for para in doc.paragraphs:\n",
    "        text += para.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "# Fix common name typos\n",
    "def fix_name_typos(text):\n",
    "    replacements = {\n",
    "        \"Gisbund\": \"Gisburn\",\n",
    "        \"Gissburn\": \"Gisburn\",\n",
    "        \"Gisbrown\": \"Gisburn\",\n",
    "        \"Grindley\": \"Grindle\",\n",
    "        \"Grindly\": \"Grindle\",\n",
    "        \"Garbuck\": \"Gisburn\",\n",
    "        \"Giesurn\": \"Gisburn\",\n",
    "        \"Gaiesurn\": \"Gisburn\",\n",
    "        \"Rickmam\": \"Rickham\",\n",
    "        \"Rickmham\": \"Rickham\",\n",
    "        \"Strud\": \"Stroud\",\n",
    "        \"Mrs. Studrd\": \"Mrs. Stroud\",\n",
    "        \"Mrs. Pardiggler\": \"Mrs. Stroud\",\n",
    "        \"Mr. Strud\": \"Mr. Stroud\",\n",
    "        \"Mrs. Pardiggle\": \"Mrs. Stroud\"\n",
    "    }\n",
    "\n",
    "    for wrong, correct in replacements.items():\n",
    "        text = re.sub(rf\"\\b{wrong}\\b\", correct, text)\n",
    "    return text\n",
    "\n",
    "# Remove repeated sentences\n",
    "def remove_repeated_sentences(text):\n",
    "    sentences = text.split('. ')\n",
    "    seen = set()\n",
    "    cleaned = []\n",
    "    for sentence in sentences:\n",
    "        sentence_clean = sentence.strip()\n",
    "        if sentence_clean and sentence_clean not in seen:\n",
    "            cleaned.append(sentence_clean)\n",
    "            seen.add(sentence_clean)\n",
    "    return '. '.join(cleaned).strip()\n",
    "\n",
    "# Ensure clean sentence endings\n",
    "def clean_endings(text):\n",
    "    if not text.endswith('.'):\n",
    "        text += '.'\n",
    "    return text.replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9f57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import traceback\n",
    "\n",
    "def summarize_file(file):\n",
    "    try:\n",
    "        if file.name.endswith(\".pdf\"):\n",
    "            text = read_pdf(file.name)\n",
    "        elif file.name.endswith(\".docx\"):\n",
    "            text = read_docx(file.name)\n",
    "        elif file.name.endswith(\".txt\"):\n",
    "            with open(file.name, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            return \"Unsupported file format. Upload .txt, .pdf, or .docx files only.\"\n",
    "\n",
    "        chunks = chunk_text(text, max_tokens=1000)\n",
    "        combined_summary = \"\"\n",
    "        for chunk in chunks:\n",
    "            prompt = f\"Summarize the following text in simple terms:\\n\\n{chunk}\\n\\nSummary:\"\n",
    "            summary = generate_response(prompt)\n",
    "            cleaned_summary = summary.split(\"Summary:\")[-1].strip()\n",
    "            combined_summary += f\"{cleaned_summary} \"\n",
    "\n",
    "        # üîß Post-Processing Pipeline\n",
    "        combined_summary = fix_name_typos(combined_summary)\n",
    "        combined_summary = remove_repeated_sentences(combined_summary)\n",
    "        combined_summary = clean_endings(combined_summary)\n",
    "\n",
    "        return combined_summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred:\\n{traceback.format_exc()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1780990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draft_content(topic, tone):\n",
    "    try:\n",
    "        prompt = (\n",
    "            f\"Write a {tone.lower()} email about the following topic:\\n\\n{topic}\\n\\n\"\n",
    "            f\"Only output the email content, including a professional closing and signature line.\"\n",
    "        )\n",
    "\n",
    "        response = generate_response(prompt).strip()\n",
    "\n",
    "        # üîß Remove leaked prompt before \"Subject:\"\n",
    "        if \"Subject:\" in response:\n",
    "            response = response.split(\"Subject:\", 1)[-1].strip()\n",
    "            response = \"Subject: \" + response\n",
    "\n",
    "        # üîß Auto-correct known typos\n",
    "        response = response.replace(\"responsibilled\", \"responsibilities\")\n",
    "        response = response.replace(\"Prime Minster\", \"Prime Minister\")\n",
    "        response = response.replace(\"Moddi\", \"Modi\")\n",
    "        response = response.replace(\"India'\", \"India's\")\n",
    "\n",
    "        # üîß Stop if AI starts another task or appends instructions\n",
    "        stop_phrases = [\n",
    "            \"Write a\", \"Instruction:\", \"Task:\", \"Next:\", \"Question:\"\n",
    "        ]\n",
    "        for phrase in stop_phrases:\n",
    "            if phrase in response:\n",
    "                response = response.split(phrase)[0].strip()\n",
    "\n",
    "        # üîß Remove unwanted signature fields\n",
    "        for unwanted in [\"[Title]\", \"[Company Name]\"]:\n",
    "            response = response.replace(unwanted, \"\").strip()\n",
    "\n",
    "        # üîß Ensure clean sentence or proper email signature ending\n",
    "        signature_phrases = [\"Sincerely,\", \"Regards,\", \"Best regards,\", \"Thank you,\", \"Yours sincerely,\", \"Warm regards,\"]\n",
    "        has_signature = any(sig in response for sig in signature_phrases)\n",
    "\n",
    "        if not has_signature:\n",
    "            if not response.endswith(('.', '!', '?')):\n",
    "                last_period = response.rfind('.')\n",
    "                if last_period != -1:\n",
    "                    response = response[:last_period+1]\n",
    "                else:\n",
    "                    response += \".\"\n",
    "\n",
    "        else:\n",
    "            # Remove trailing text after signature if it leaks\n",
    "            lines = response.splitlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                if any(sig in line for sig in signature_phrases):\n",
    "                    response = \"\\n\".join(lines[:i+2])  # Keep signature + name\n",
    "                    break\n",
    "\n",
    "        # üîß Remove leaked prompts or instructions AFTER the signature\n",
    "        leaked_phrases = [\n",
    "            \"Compose an in-depth\", \"Please write\", \"Generate a\",\n",
    "            \"Write an analysis\", \"Create a report\", \"Answer the following\"\n",
    "        ]\n",
    "        for phrase in leaked_phrases:\n",
    "            if phrase in response:\n",
    "                response = response.split(phrase)[0].strip()\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return f\"Error occurred:\\n{traceback.format_exc()}\"\n",
    "\n",
    "import re\n",
    "\n",
    "def draft_content(topic, tone):\n",
    "    try:\n",
    "        # üö´ Detect general questions or unrelated prompts\n",
    "        question_keywords = [\"what\", \"why\", \"how\", \"when\", \"who\", \"which\", \"is\", \"are\", \"do\", \"does\", \"should\"]\n",
    "        if topic.strip().endswith(\"?\") or re.match(r\"^\\s*(\" + \"|\".join(question_keywords) + r\")\\b\", topic.strip().lower()):\n",
    "            return (\n",
    "                \"üìù This email drafting tool is designed for creating professional or friendly emails based on a specific topic.\\n\"\n",
    "                \"It looks like you've entered a general question. Please use a different tool or interface for general queries.\"\n",
    "            )\n",
    "\n",
    "        prompt = (\n",
    "            f\"Write a {tone.lower()} email about the following topic:\\n\\n{topic}\\n\\n\"\n",
    "            f\"Only output the email content, including a professional closing and signature line.\"\n",
    "        )\n",
    "\n",
    "        response = generate_response(prompt).strip()\n",
    "\n",
    "        # üîß Remove leaked prompt before \"Subject:\"\n",
    "        if \"Subject:\" in response:\n",
    "            response = response.split(\"Subject:\", 1)[-1].strip()\n",
    "            response = \"Subject: \" + response\n",
    "\n",
    "        # üîß Auto-correct known typos\n",
    "        response = response.replace(\"responsibilled\", \"responsibilities\")\n",
    "\n",
    "        # üîß Stop if AI starts another task\n",
    "        for stop_phrase in [\"Write a\", \"Instruction:\", \"Task:\", \"Next:\", \"Question:\"]:\n",
    "            if stop_phrase in response:\n",
    "                response = response.split(stop_phrase)[0].strip()\n",
    "\n",
    "        # üîß Remove unwanted signature fields\n",
    "        for unwanted in [\"[Title]\", \"[Company Name]\"]:\n",
    "            response = response.replace(unwanted, \"\").strip()\n",
    "\n",
    "        # üîß Ensure clean sentence ending (if no signature exists)\n",
    "        signature_phrases = [\"Sincerely,\", \"Regards,\", \"Best regards,\", \"Thank you,\", \"Yours sincerely,\"]\n",
    "        has_signature = any(sig in response for sig in signature_phrases)\n",
    "\n",
    "        if not has_signature:\n",
    "            if not response.endswith(('.', '!', '?')):\n",
    "                last_period = response.rfind('.')\n",
    "                if last_period != -1:\n",
    "                    response = response[:last_period+1]\n",
    "                else:\n",
    "                    response += \"...\"\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return f\"Error occurred:\\n{traceback.format_exc()}\"\n",
    "\n",
    "\"\"\"üîπ AI Response Generation Function\n",
    "\n",
    "This function creates structured AI-generated text with controlled length and coherence.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "‚úÖ Processes input using tokenization.\n",
    "\n",
    "‚úÖ Generates text with constraints to prevent randomness and repetition.\n",
    "\n",
    "‚úÖ Ensures clean stopping using an end-of-sequence token.\n",
    "\n",
    "‚úÖ Decodes output into readable text.\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=350,  # Enough for full email + signature\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=False,\n",
    "            no_repeat_ngram_size=3,\n",
    "            eos_token_id=tokenizer.eos_token_id  # Stops cleanly\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\"\"\"üåê Unified Gradio Interface ‚Äì VersaMind\"\"\"\n",
    "\n",
    "# --- GRADIO INTERFACE ---\n",
    "with gr.Blocks(title=\"üß† VersaMind ‚Äì Smart Summarizer & Email Drafter\") as app:\n",
    "    gr.Markdown(\"# üß† VersaMind ‚Äì Smart Summarizer & Email Drafter\")\n",
    "    gr.Markdown(\"Upload documents or enter a topic to quickly get AI-generated summaries or professional emails!\")\n",
    "\n",
    "    with gr.Tab(\"üìÑ Document Summarizer\"):\n",
    "        file_input = gr.File(label=\"üìÑ Upload .txt, .pdf, or .docx file\")\n",
    "        summary_output = gr.Textbox(label=\"üìù Summary\", lines=10)\n",
    "        summarize_btn = gr.Button(\"Summarize\")\n",
    "        summarize_btn.click(fn=summarize_file, inputs=file_input, outputs=summary_output)\n",
    "\n",
    "    with gr.Tab(\"‚úâÔ∏è Email Drafter\"):\n",
    "        topic_input = gr.Textbox(label=\"üìù Enter Topic or Prompt\", lines=2)\n",
    "        tone_input = gr.Radio([\"Formal\", \"Friendly\", \"Professional\", \"Casual\"], label=\"Select Style/Tone\")\n",
    "        draft_output = gr.Textbox(label=\"üñãÔ∏è Drafted Email\", lines=10)\n",
    "        draft_btn = gr.Button(\"Draft Email\")\n",
    "        draft_btn.click(fn=draft_content, inputs=[topic_input, tone_input], outputs=draft_output)\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
